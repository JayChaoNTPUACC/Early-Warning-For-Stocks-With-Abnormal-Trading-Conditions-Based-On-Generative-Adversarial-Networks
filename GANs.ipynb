{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0kytTMdpUbSPA5dP1eqU3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"0Pgp0D4xMyDn","executionInfo":{"status":"ok","timestamp":1703420499443,"user_tz":-480,"elapsed":392,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"outputs":[],"source":["# #安裝套件\n","# !pip install tensorflow\n","# !pip install keras"]},{"cell_type":"code","source":["# # 使用gpu\n","# import tensorflow.compat.v1 as tf\n","# tf.disable_v2_behavior()\n","\n","# device_name = tf.test.gpu_device_name()\n","# # if device_name != '/device:GPU:0':\n","# #   raise SystemError('GPU device not found')\n","# print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"Hml-UpfHIU24","executionInfo":{"status":"ok","timestamp":1703420500017,"user_tz":-480,"elapsed":5,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 掛載雲端硬碟\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OrOeRLwIW5K","executionInfo":{"status":"ok","timestamp":1703420504097,"user_tz":-480,"elapsed":4084,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}},"outputId":"5fb15f4a-10a8-41a9-a638-8ac39cc75285"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive\""],"metadata":{"id":"Wu-d0jbuKvdW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703420504097,"user_tz":-480,"elapsed":5,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}},"outputId":"ff8c2145-3b85-44e3-d83f-b702e9faec7a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[" AIinFQA\t\t\t    '國立臺北大學 (1).png'   財經犯罪偵查心得報告.docx\n","'Colab Notebooks'\t\t    '國立臺北大學 (2).png'   財經犯罪手法與審理心得報告.docx\n"," NTPUAcc112\t\t\t     國立臺北大學.png\n"," 不動產價格趨勢與估價心得報告.docx   國際租稅\n"]}]},{"cell_type":"code","source":["# 全域變數\n","googlepath = \"drive/MyDrive/Colab Notebooks/EarlyWarningStocksGAN/EWSGAN/\""],"metadata":{"id":"dlg49ReGK1L_","executionInfo":{"status":"ok","timestamp":1703420504097,"user_tz":-480,"elapsed":3,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import time\n","import os\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from math import sqrt\n","import numpy as np\n","from keras.layers import GRU, Dense, Flatten, Conv1D, LeakyReLU, Dropout\n","from keras import Sequential\n","from pickle import load\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"j226a_WZbxnA","executionInfo":{"status":"ok","timestamp":1703420512500,"user_tz":-480,"elapsed":8406,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#global variable\n","get_last_days = 182 #30\n","googlepath = \"drive/MyDrive/Colab Notebooks/EarlyWarningStocksGAN/EWSGAN\""],"metadata":{"id":"f34xeFVRcB-6","executionInfo":{"status":"ok","timestamp":1703420512500,"user_tz":-480,"elapsed":10,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def LoadDataToList(filespath):\n","  data_list = []\n","  for file_name in os.listdir(filespath):\n","    file_path = os.path.join(filespath, file_name)\n","    loaded_data = np.load(file_path, allow_pickle=True)\n","    #print(f\"{file_name} shape: {loaded_data.shape}\")\n","    for data in loaded_data:\n","      data_list.insert(0,data)\n","  # print(data_list)\n","  return np.array(data_list)"],"metadata":{"id":"g_QpxUSrcELz","executionInfo":{"status":"ok","timestamp":1703420512500,"user_tz":-480,"elapsed":9,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load data\n","X_train = LoadDataToList(f'{googlepath}/X_train')\n","y_train = LoadDataToList(f'{googlepath}/Y_train')\n","X_test = LoadDataToList(f'{googlepath}/X_test')\n","y_test = LoadDataToList(f'{googlepath}/Y_test')\n","yc_train = LoadDataToList(f'{googlepath}/YC_train')\n","yc_test = LoadDataToList(f'{googlepath}/YC_test')"],"metadata":{"id":"fTUMf6bxcP3K","executionInfo":{"status":"ok","timestamp":1703420515796,"user_tz":-480,"elapsed":3304,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def make_generator_model(input_dim, output_dim, feature_size) -> tf.keras.models.Model:\n","\n","  model = Sequential()\n","  model.add(GRU(units=1024, return_sequences = True, input_shape=(input_dim, feature_size),\n","                recurrent_dropout=0.2))\n","  model.add(GRU(units=512, return_sequences = True, recurrent_dropout=0.2)) # 256, return_sequences = True\n","  model.add(GRU(units=256, recurrent_dropout=0.2)) #, recurrent_dropout=0.1\n","  # , recurrent_dropout = 0.2\n","  model.add(Dense(128))\n","  # model.add(Dense(128))\n","  model.add(Dense(64))\n","  #model.add(Dense(16))\n","  model.add(Dense(units=output_dim))\n","  return model"],"metadata":{"id":"vzzcmx2ncT5-","executionInfo":{"status":"ok","timestamp":1703420515796,"user_tz":-480,"elapsed":4,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def make_discriminator_model():\n","\n","  cnn_net = tf.keras.Sequential()\n","  cnn_net.add(Conv1D(32, input_shape=(4, 1), kernel_size=3, strides=2, padding='same', activation=LeakyReLU(alpha=0.01)))\n","  cnn_net.add(Conv1D(64, kernel_size=5, strides=2, padding='same', activation=LeakyReLU(alpha=0.01)))\n","  cnn_net.add(Conv1D(128, kernel_size=5, strides=2, padding='same', activation=LeakyReLU(alpha=0.01)))\n","  cnn_net.add(Flatten())\n","  cnn_net.add(Dense(220, use_bias=False))\n","  cnn_net.add(LeakyReLU())\n","  cnn_net.add(Dense(220, use_bias=False, activation='relu'))\n","  cnn_net.add(Dense(1, activation='sigmoid'))\n","  return cnn_net"],"metadata":{"id":"5KgWiCxlcXnW","executionInfo":{"status":"ok","timestamp":1703420515796,"user_tz":-480,"elapsed":3,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class GAN:\n","  def __init__(self, generator, discriminator, opt):\n","    self.opt = opt\n","    self.lr = opt[\"learning_rate\"]\n","    self.generator = generator\n","    self.discriminator = discriminator\n","    self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","    self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n","    self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n","    self.batch_size = self.opt['bs']\n","    self.checkpoint_dir = '../training_checkpoints'\n","    self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n","    self.checkpoint = tf.train.Checkpoint(generator_optimizer=self.generator_optimizer,\n","                                          discriminator_optimizer=self.discriminator_optimizer,\n","                                          generator=self.generator,\n","                                          discriminator=self.discriminator)\n","\n","  def discriminator_loss(self, real_output, fake_output):\n","    real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","  def generator_loss(self, fake_output):\n","    return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","  @tf.function\n","  def train_step(self, real_x, real_y, yc):\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","      generated_data = self.generator(real_x, training=True)\n","      generated_data_reshape = tf.reshape(generated_data, [generated_data.shape[0], generated_data.shape[1], 1])\n","      d_fake_input = tf.concat([tf.cast(generated_data_reshape, tf.float64), yc], axis=1)\n","      real_y_reshape = tf.reshape(real_y, [real_y.shape[0], real_y.shape[1], 1])\n","      d_real_input = tf.concat([real_y_reshape, yc], axis=1)\n","\n","      # #Reshape for MLP\n","      # d_fake_input = tf.reshape(d_fake_input, [d_fake_input.shape[0], d_fake_input.shape[1]])\n","      d_fake_input = d_fake_input[:, :4, :]\n","      # d_real_input = tf.reshape(d_real_input, [d_real_input.shape[0], d_real_input.shape[1]])\n","      d_real_input = d_real_input[:, :4, :]\n","\n","      real_output = self.discriminator(d_real_input, training=True)\n","      fake_output = self.discriminator(d_fake_input, training=True)\n","\n","      gen_loss = self.generator_loss(fake_output)\n","      disc_loss = self.discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n","\n","    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n","    self.discriminator_optimizer.apply_gradients(\n","        zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n","    return real_y, generated_data, {'d_loss': disc_loss, 'g_loss': gen_loss}\n","\n","  def train(self, real_x, real_y, yc, opt):\n","    train_hist = {}\n","    train_hist['D_losses'] = []\n","    train_hist['G_losses'] = []\n","    train_hist['per_epoch_times'] = []\n","    train_hist['total_ptime'] = []\n","\n","    epochs = opt[\"epoch\"]\n","    for epoch in range(epochs):\n","      start = time.time()\n","\n","      real_price, fake_price, loss = self.train_step(real_x, real_y, yc)\n","\n","      G_losses = []\n","      D_losses = []\n","\n","      Real_price = []\n","      Predicted_price = []\n","\n","      D_losses.append(loss['d_loss'].numpy())\n","      G_losses.append(loss['g_loss'].numpy())\n","\n","      Predicted_price.append(fake_price.numpy())\n","      Real_price.append(real_price.numpy())\n","\n","      # Save the model every 15 epochs\n","      if (epoch + 1) % 15 == 0:\n","        tf.keras.models.save_model(generator, 'gen_model_%d.h5' % epoch)\n","        self.checkpoint.save(file_prefix=self.checkpoint_prefix + f'-{epoch}')\n","        print('epoch', epoch + 1, 'd_loss', loss['d_loss'].numpy(), 'g_loss', loss['g_loss'].numpy())\n","      print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n","      # For printing loss\n","      epoch_end_time = time.time()\n","      per_epoch_ptime = epoch_end_time - start\n","      train_hist['D_losses'].append(D_losses)\n","      train_hist['G_losses'].append(G_losses)\n","      train_hist['per_epoch_times'].append(per_epoch_ptime)\n","\n","    # Reshape the predicted result & real\n","    Predicted_price = np.array(Predicted_price)\n","    Predicted_price = Predicted_price.reshape(Predicted_price.shape[1], Predicted_price.shape[2])\n","    Real_price = np.array(Real_price)\n","    Real_price = Real_price.reshape(Real_price.shape[1], Real_price.shape[2])\n","\n","    plt.plot(train_hist['D_losses'], label='D_loss')\n","    plt.plot(train_hist['G_losses'], label='G_loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    return Predicted_price, Real_price,sqrt(mean_squared_error(Real_price, Predicted_price)) , np.sqrt(mean_squared_error(Real_price, Predicted_price)) / np.mean(\n","        Real_price)"],"metadata":{"id":"wxLKxy2Yca_Y","executionInfo":{"status":"ok","timestamp":1703420515796,"user_tz":-480,"elapsed":3,"user":{"displayName":"趙世傑","userId":"13684111213541078084"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["input_dim = X_train.shape[1]\n","feature_size = X_train.shape[2]\n","output_dim = y_train.shape[1]\n","\n","## For Bayesian\n","opt = {\"learning_rate\": 0.001, \"epoch\": 50, 'bs': 64}\n","\n","generator = make_generator_model(X_train.shape[1], output_dim, X_train.shape[2])\n","discriminator = make_discriminator_model()\n","gan = GAN(generator, discriminator, opt)\n","Predicted_price, Real_price, RMSE, RMSPE = gan.train(X_train, y_train, yc_train, opt)\n","\n","print(f'RMSE:{RMSE}')\n","print(f'RMSPE:{RMSPE}')"],"metadata":{"id":"UVX-Q2gmceM6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"461269c0-3ad8-45a5-94d2-8a7501b1e5db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]}]}]}